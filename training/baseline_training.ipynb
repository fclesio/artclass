{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65bbe286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a66de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "ROOT_DIR = path.abspath(path.join(os.getcwd(),\"..\"))\n",
    "training_data_path = ROOT_DIR + '/data/training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cdc2f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.walk(ROOT_DIR + '/data/training/')\n",
    "#data_directories = [x[0] for x in os.walk(ROOT_DIR + '/data/training/')]\n",
    "#data_directories.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9abdc216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "all_images = []\n",
    "\n",
    "directory = os.path.realpath(training_data_path)\n",
    "for subdir, dirs, files in os.walk(directory):\n",
    "     for filename in files:\n",
    "            subdirectoryPath = os.path.relpath(subdir, directory) \n",
    "            file1 = os.path.join(directory,subdirectoryPath)\n",
    "            filePath = os.path.join(file1, filename)\n",
    "            \n",
    "            all_images.append(filePath)\n",
    "            \n",
    "            try:\n",
    "                fobj = open(filePath, \"rb\")\n",
    "                is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "            finally:\n",
    "                fobj.close()\n",
    "\n",
    "            if not is_jfif:\n",
    "                os.remove(filePath)                \n",
    "                print(f'File {filePath} deleted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c70ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dd7b9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42603/42603 [02:19<00:00, 305.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from struct import unpack\n",
    "marker_mapping = {\n",
    "    0xffd8: \"Start of Image\",\n",
    "    0xffe0: \"Application Default Header\",\n",
    "    0xffdb: \"Quantization Table\",\n",
    "    0xffc0: \"Start of Frame\",\n",
    "    0xffc4: \"Define Huffman Table\",\n",
    "    0xffda: \"Start of Scan\",\n",
    "    0xffd9: \"End of Image\"\n",
    "}\n",
    "\n",
    "\n",
    "class JPEG:\n",
    "    def __init__(self, image_file):\n",
    "        with open(image_file, 'rb') as f:\n",
    "            self.img_data = f.read()\n",
    "    \n",
    "    def decode(self):\n",
    "        data = self.img_data\n",
    "        while(True):\n",
    "            marker, = unpack(\">H\", data[0:2])\n",
    "            # print(marker_mapping.get(marker))\n",
    "            if marker == 0xffd8:\n",
    "                data = data[2:]\n",
    "            elif marker == 0xffd9:\n",
    "                return\n",
    "            elif marker == 0xffda:\n",
    "                data = data[-2:]\n",
    "            else:\n",
    "                lenchunk, = unpack(\">H\", data[2:4])\n",
    "                data = data[2+lenchunk:]            \n",
    "            if len(data)==0:\n",
    "                break        \n",
    "\n",
    "\n",
    "bads = []\n",
    "\n",
    "for img in tqdm(all_images):\n",
    "    #image = os.join(root_img,img)\n",
    "    image = JPEG(img) \n",
    "    try:\n",
    "        image.decode()   \n",
    "    except:\n",
    "        bads.append(img)\n",
    "\n",
    "\n",
    "for name in bads:\n",
    "    os.remove(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d04f2e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd40d537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42603 files belonging to 27 classes.\n",
      "Using 34083 files for training.\n",
      "Found 42603 files belonging to 27 classes.\n",
      "Using 8520 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = (256, 256)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    training_data_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    labels=\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    training_data_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d210e6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bronze', 'ceramic', 'copper', 'earthenware', 'etching', 'faience', 'glass', 'gold', 'graphite', 'ink', 'iron', 'ivory', 'limestone', 'linen', 'marble', 'on_canvas', 'porcelain', 'pottery', 'print', 'salted_paper', 'silk', 'silver', 'steel', 'stone', 'terracotta', 'watercolor', 'wool']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa8578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d039a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc580a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e6dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(buffer_size=32)\n",
    "val_ds = val_ds.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7680a46e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#def make_model(input_shape, num_classes):\n",
    "\n",
    "input_shape = image_size + (3,)\n",
    "num_classes=27\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "# Image augmentation block\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "# Entry block\n",
    "x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n",
    "x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "previous_block_activation = x  # Set aside residual\n",
    "\n",
    "for size in [128, 256, 512, 728]:\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "    # Project residual\n",
    "    residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "        previous_block_activation\n",
    "    )\n",
    "    x = layers.add([x, residual])  # Add back residual\n",
    "    previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "if num_classes == 2:\n",
    "    activation = \"sigmoid\"\n",
    "    units = 1\n",
    "    loss_function = \"binary_crossentropy\"\n",
    "    \n",
    "else:\n",
    "    activation = \"softmax\"\n",
    "    units = num_classes\n",
    "    loss_function = \"sparse_categorical_crossentropy\"\n",
    "\n",
    "print(f'Num Classes: {num_classes}')\n",
    "print(f'Num units: {units}')\n",
    "\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(units, activation=activation)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=loss_function,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb948fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b074517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_training.ipynb  save_at_5.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14a79309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model('save_at_5.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1aedbf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = '/home/studioml/Desktop/github/capivara/data/training/bronze/9168_46165be80d124b958cb054505e93a527_.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "250169c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path):\n",
    "\n",
    "    image_transformed = keras.preprocessing.image.load_img(\n",
    "        image_path, target_size=(256, 256))\n",
    "    \n",
    "    image_array = keras.preprocessing.image.img_to_array(image_transformed)\n",
    "    image_array_batch = tf.expand_dims(image_array, 0)\n",
    "\n",
    "    prediction = model.predict(image_array_batch)\n",
    "    score = tf.nn.softmax(prediction[0])\n",
    "\n",
    "    print(f\"This image most likely belongs to {class_names[np.argmax(score)]} with a {round(100 * np.max(score), 2)} % confidence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc0f5ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to bronze with a 7.54 % confidence.\n"
     ]
    }
   ],
   "source": [
    "predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9bd210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a33189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
